{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4==0.0.1\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crawling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 crawling Stadiums data and matches data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_stadium(season_start_year=1992):\n",
    "\n",
    "    international_history = 'https://www.worldfootball.net/venues/eng-premier-league-{}-{}/'.format(season_start_year, season_start_year+1)\n",
    "    page = requests.get(international_history)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    table = soup.findAll('table')[0]\n",
    "    tds = table.find_all('td')\n",
    "\n",
    "    data = []\n",
    "    for row_index in range(int(len(tds)/6)):\n",
    "        \n",
    "        current_position = row_index * 6\n",
    "\n",
    "        stadium_name = tds[current_position + 1].text\n",
    "        \n",
    "        href = list(tds[current_position + 1].children)[0]['href']\n",
    "        city = tds[current_position + 2].text\n",
    "        capacity = tds[current_position + 5].text\n",
    "\n",
    "        data.append((stadium_name, href, city, capacity))\n",
    "\n",
    "    data = pd.DataFrame(data, columns=['stadium_name', 'href', 'city', 'capacity'])\n",
    "    data.to_csv('datasets/stadiums/{}-{}_stadiums.csv'.format(season_start_year, season_start_year+1))\n",
    "    print('finish {}-{}'.format(season_start_year, season_start_year+1))\n",
    "\n",
    "\n",
    "# matches data\n",
    "def crawl_matches_by_stadium(href, year, nth):\n",
    "\n",
    "    url = 'https://www.worldfootball.net{}{}/2/'.format(href, year)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    table = soup.findAll('table')[1]\n",
    "    tds = table.find_all('td')\n",
    "\n",
    "    data = []\n",
    "    for row_index in range(int(len(tds)/7)):\n",
    "        \n",
    "        current_position = row_index * 7\n",
    "\n",
    "        match_type = tds[current_position + 0].text\n",
    "        date = tds[current_position + 1].text\n",
    "        home_team = tds[current_position + 2].a['href'].split('/')[2] if tds[current_position + 2].a else tds[current_position + 2].text\n",
    "        away_team = tds[current_position + 4].a['href'].split('/')[2] if tds[current_position + 4].a else tds[current_position + 4].text\n",
    "        result = tds[current_position + 5].text\n",
    "        capacity = tds[current_position + 6].text\n",
    "\n",
    "        data.append((match_type, date, home_team, away_team, result, capacity))\n",
    "\n",
    "    season = '{}-{}'.format(1991+nth, 1992+nth)\n",
    "    stadium = href.split('/')[2]\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=['match_type', 'date', 'home_team', 'away_team', 'result', 'capacity'])\n",
    "    if os.path.isdir('datasets/matches/{}/'.format(season)) == False:\n",
    "        os.makedirs('datasets/matches/{}/'.format(season))\n",
    "    path = 'datasets/matches/{}/{}_{}.csv'.format(season, stadium, year)\n",
    "    data.to_csv(path)\n",
    "    print('finish {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl each season stasium data\n",
    "for i in range(1992, 2022):\n",
    "    crawl_stadium(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "# get all data\n",
    "for filename in os.listdir('datasets/stadiums'):\n",
    "    stadiums = pd.read_csv('datasets/stadiums/{}'.format(filename))\n",
    "    for i, row in stadiums.iterrows():\n",
    "        year1, year2 = filename.split('_')[0].split('-')\n",
    "        crawl_matches_by_stadium(row['href'], year1, int(year1)-1991)\n",
    "        time.sleep(3)\n",
    "        crawl_matches_by_stadium(row['href'], year2, int(year1)-1991)\n",
    "        time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 2021-2022\n",
      "finish datasets/matches/2021-2022/amex-stadium-brighton_2022.csv\n",
      "finish datasets/matches/2021-2022/anfield-liverpool_2022.csv\n",
      "finish datasets/matches/2021-2022/brentford-community-stadium-brentford_2022.csv\n",
      "finish datasets/matches/2021-2022/carrow-road-norwich_2022.csv\n",
      "finish datasets/matches/2021-2022/elland-road-leeds_2022.csv\n",
      "finish datasets/matches/2021-2022/emirates-stadium-london_2022.csv\n",
      "finish datasets/matches/2021-2022/etihad-stadium-manchester_2022.csv\n",
      "finish datasets/matches/2021-2022/goodison-park-liverpool_2022.csv\n",
      "finish datasets/matches/2021-2022/king-power-stadium-leicester_2022.csv\n",
      "finish datasets/matches/2021-2022/london-stadium-london_2022.csv\n",
      "finish datasets/matches/2021-2022/molineux-stadium-wolverhampton_2022.csv\n",
      "finish datasets/matches/2021-2022/old-trafford-manchester_2022.csv\n",
      "finish datasets/matches/2021-2022/saint-marys-southampton_2022.csv\n",
      "finish datasets/matches/2021-2022/selhurst-park-london_2022.csv\n",
      "finish datasets/matches/2021-2022/st-james-park-newcastle_2022.csv\n",
      "finish datasets/matches/2021-2022/stamford-bridge-london_2022.csv\n",
      "finish datasets/matches/2021-2022/tottenham-hotspur-stadium-london_2022.csv\n",
      "finish datasets/matches/2021-2022/turf-moor-burnley_2022.csv\n",
      "finish datasets/matches/2021-2022/vicarage-road-watford_2022.csv\n",
      "finish datasets/matches/2021-2022/villa-park-birmingham_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# update 2022 data\n",
    "def update2022():\n",
    "    crawl_stadium(2021)\n",
    "    stadiums = pd.read_csv('datasets/stadiums/2021-2022_stadiums.csv')\n",
    "    for i, row in stadiums.iterrows():\n",
    "        crawl_matches_by_stadium(row['href'], '2022', int(2021)-1991)\n",
    "        time.sleep(3)\n",
    "        \n",
    "update2022()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b774acfeff12025bb88a6812344d10674551d33b3b06a1f7dd54b9641286f7ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
